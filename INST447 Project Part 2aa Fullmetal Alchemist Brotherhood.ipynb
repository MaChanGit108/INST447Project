{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INST447 Project Part 2\n",
    "#### Members: Alexander Chui and Matthew Chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What factors affect ratings for an anime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen \n",
    "import numpy as np\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries imported for handling rate limits and console formatting\n",
    "from time import time, sleep\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "from IPython.core.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:164: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:281: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:865: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1121: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1149: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1379: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1621: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1755: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\Users\\MaNinjaChan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:172: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "\n",
    "import nltk; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the URL on the web to access its content (Crunchyroll)\n",
    "# html=urlopen('https://www.crunchyroll.com/fullmetal-alchemist-brotherhood/reviews/helpful/page1')\n",
    "# html.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connecting to the URL on the web to access its content (MAL)\n",
    "html=urlopen('https://myanimelist.net/anime/5114/Fullmetal_Alchemist__Brotherhood/reviews?p=1')\n",
    "html.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an instance of beautifulsoup object to begin web scraping\n",
    "bs=BeautifulSoup(html.read(),'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#Acessing the container objects with the anime info \n",
    "anime_review_containers = bs.find_all('div', {'class':{'borderDark'}})\n",
    "print(len(anime_review_containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store all the items \n",
    "review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the monitoring of the loop\n",
    "start_time = time()\n",
    "request = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting each job name in loop\n",
    "for page in range(1,41):\n",
    "    # Make a get request\n",
    "        #https://myanimelist.net/anime/genre/1/Action?page=1\n",
    "        #https://myanimelist.net/anime/genre/1/Action?page=2\n",
    "        response = get('https://myanimelist.net/anime/5114/Fullmetal_Alchemist__Brotherhood/reviews?p='+ str(page))\n",
    "        \n",
    "#         # Pause the loop\n",
    "#         sleep(randint(8,15))\n",
    "\n",
    "#         # Monitor the requests\n",
    "#         request += 1\n",
    "#         elapsed_time = time() - start_time\n",
    "#         print('Request:{}; Frequency: {} requests/s'.format(request, \n",
    "#                                                             request/elapsed_time))\n",
    "#         clear_output(wait = True)\n",
    "\n",
    "#         # Throw a warning for non-200 status codes\n",
    "#         if response.status_code != 200:\n",
    "#             warn('Request: {}; Status code: {}'.format(request, \n",
    "#                                                        response.status_code))\n",
    "\n",
    "#         # Break the loop if the number of requests is greater than expected\n",
    "#         if request > 100:\n",
    "#             warn('Number of requests was greater than expected.')\n",
    "#             break\n",
    "        \n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        bs = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        #Acessing the container objects with the anime info \n",
    "        anime_review_containers = bs.find_all('div', {'class':{'borderDark'}})\n",
    "\n",
    "        #Extracting all the elements \n",
    "        for container in anime_review_containers:\n",
    "        # If the movie has Metascore, then extract:\n",
    "        #  if container.find('div', {'class':{'scoremem'}})  is not None:\n",
    "        \n",
    "        # The name of anime\n",
    "            try: \n",
    "                reviews = container.find('div', {'class':'spaceit textReadability word-break pt8 mt8'})\n",
    "                review.append(reviews.text)\n",
    "            except:\n",
    "                review.append('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  800 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 6.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Creating a pandas dataframe to store the objects extracted\n",
    "anime_review = pd.DataFrame({'Review': review\n",
    "})\n",
    "print(anime_review.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\nOverall\\n10\\n\\n\\nStory\\n10\\n\\n\\nAnimat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\nOverall\\n9\\n\\n\\nStory\\n8\\n\\n\\nAnimatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\nOverall\\n7\\n\\n\\nStory\\n8\\n\\n\\nAnimatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\nOverall\\n7\\n\\n\\nStory\\n8\\n\\n\\nAnimatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n\\nOverall\\n3\\n\\n\\nStory\\n2\\n\\n\\nAnimatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  \\n\\n\\n\\nOverall\\n10\\n\\n\\nStory\\n10\\n\\n\\nAnimat...\n",
       "1  \\n\\n\\n\\nOverall\\n9\\n\\n\\nStory\\n8\\n\\n\\nAnimatio...\n",
       "2  \\n\\n\\n\\nOverall\\n7\\n\\n\\nStory\\n8\\n\\n\\nAnimatio...\n",
       "3  \\n\\n\\n\\nOverall\\n7\\n\\n\\nStory\\n8\\n\\n\\nAnimatio...\n",
       "4  \\n\\n\\n\\nOverall\\n3\\n\\n\\nStory\\n2\\n\\n\\nAnimatio..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the top 5 rows of dataset\n",
    "anime_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-15-b412c0db5fd7>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "  data = [re.sub('\\s+', ' ', sent) for sent in data]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Overall 10 Story 10 Animation 9 Sound 9 Character 10 Enjoyment 10 First of all, I have seen the original FMA and although it was very popular and original, the pacing and conclusion did not sit too well with me. Brotherhood is meant to be a remake of the original, this time sticking to the manga all the way through, but there were people who thought it would spoil the franchise. That myth should be dispelled, as there's only one word to describe this series - EPIC. I admit that as I've seen the original and read the manga, the pacing of Brotherhood seems to start off being VERY fast (I finally got used to the pacing after watching the first fifteen eps or so). Events that took up half a volume of the manga and had spread though a few episodes of the original anime were now shown in just a single episode. However, after trying to look at it from the perspective of someone who's new to FMA (not comparing it to the manga nor the original), I believe that the pacing works and it manages to tell an intriguing story effectively with little confusion. The plot is full of clever ideas and unpredictable twists that link various parts of the story together. By the final episode, all loose ends are neatly tied up and what's left is a hugely satisfying epilogue. The animation in FMA Brotherhood is crisp and very well done (although it does sometimes dip a bit in quality). Compared to the original FMA it's a bit simpler but that's just because the original set a very high standard to follow. The facial emotions of the characters are also perfectly presented. The action scenes are brilliant and VERY well animated, with a variety of alchemy techniques and other talents being displayed nearly every episode. The various battles are consistently exciting to watch, but somehow get even better towards the end of the series. The voice acting is of an excellent and consistent quality, and I think that pretty much all the characters have voice actors which suit their personalities. The majority of the openings/endings are a pleasure to watch due to fantastic animated sequences and theme songs. The background music which play during the episodes usually fit very well with the situation, although some tracks seem to be overused a little at first. This becomes less of a problem as the series progresses, with plenty of new music being introduced to support the story as it reaches the finale. Moving on to the characters (best thing about this series), the original FMA focussed mainly on Ed and Al and on their struggles to regain their bodies, whereas Brotherhood also explores other characters to great detail at the same time. The majority of the spotlight is still on the two brothers, but it highlights their interactions with new characters which were not present in the original anime. New characters include a group of people from Xing (a neighbouring country), another person from the Armstrong family (who I think has become one of the coolest members of the supporting cast), and a new main antagonist. For me, the Xingese characters in particular (Ling Yao and Mei Chang among others) provide a new dimension to the FMA world, by showing us a different culture to the militaristic one we're familiar with. I think the new antagonist is an improvement on the original FMA, as this person has a much stronger and clever link to the Elric brothers' father. Returning characters from the original FMA, such as Mustang and Scar, are much more awesome and developed due to the fact that Brotherhood is 100% faithful to the manga. Plus, Winry Rockbell now has a much more active role in the story. I can say for sure that this anime has one of the best main/supporting casts I've ever seen, and you'd probably find it difficult to label any of the recurring characters (whether they are good or evil) as being either boring or unnecessary in terms of the storyline. One of the many good things about this series is that there has been absolutely no filler at all (yes, I'm thinking of Naruto, Inuyasha, etc), which prevents the story from losing momentum. All the episodes are concise and every scene is important as part of the huge plot. The dialogue fully explains everything and is straight to the point. As multiple characters are explored there are lots of side stories, but these are all perfectly intertwined with the main story of the Elric brothers and more often than not directly influence their journey too. Like most anime series, there are things from the manga which have been left out, but these are usually just restricted to comedy moments. There has been one episode which shows a lot of flashbacks of events so far, but that's forgiven as it shows the most epic moments of the series, and also provided us with some history on the father of the Elric brothers. FMA Brotherhood will be sorely missed now that it's finished. It is excellent in every aspect and has very little, if anything, that can be called a flaw (maybe rushed character development at first due to the fast pacing, but this quickly subsides). Each episode feels like it's too short, a testimony to how much it draws you in to the story and characters. There are moments which leave you smiling, laughing, sad and simply amazed. Try this anime, it's recommended for absolutely everyone, to newcomers and to those familiar with Fullmetal Alchemist. Helpful read more \n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = anime_review['Review'].tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overall', 'story', 'animation', 'sound', 'character', 'enjoyment', 'first', 'of', 'all', 'have', 'seen', 'the', 'original', 'fma', 'and', 'although', 'it', 'was', 'very', 'popular', 'and', 'original', 'the', 'pacing', 'and', 'conclusion', 'did', 'not', 'sit', 'too', 'well', 'with', 'me', 'brotherhood', 'is', 'meant', 'to', 'be', 'remake', 'of', 'the', 'original', 'this', 'time', 'sticking', 'to', 'the', 'manga', 'all', 'the', 'way', 'through', 'but', 'there', 'were', 'people', 'who', 'thought', 'it', 'would', 'spoil', 'the', 'franchise', 'that', 'myth', 'should', 'be', 'dispelled', 'as', 'there', 'only', 'one', 'word', 'to', 'describe', 'this', 'series', 'epic', 'admit', 'that', 'as', 've', 'seen', 'the', 'original', 'and', 'read', 'the', 'manga', 'the', 'pacing', 'of', 'brotherhood', 'seems', 'to', 'start', 'off', 'being', 'very', 'fast', 'finally', 'got', 'used', 'to', 'the', 'pacing', 'after', 'watching', 'the', 'first', 'fifteen', 'eps', 'or', 'so', 'events', 'that', 'took', 'up', 'half', 'volume', 'of', 'the', 'manga', 'and', 'had', 'spread', 'though', 'few', 'episodes', 'of', 'the', 'original', 'anime', 'were', 'now', 'shown', 'in', 'just', 'single', 'episode', 'however', 'after', 'trying', 'to', 'look', 'at', 'it', 'from', 'the', 'perspective', 'of', 'someone', 'who', 'new', 'to', 'fma', 'not', 'comparing', 'it', 'to', 'the', 'manga', 'nor', 'the', 'original', 'believe', 'that', 'the', 'pacing', 'works', 'and', 'it', 'manages', 'to', 'tell', 'an', 'intriguing', 'story', 'effectively', 'with', 'little', 'confusion', 'the', 'plot', 'is', 'full', 'of', 'clever', 'ideas', 'and', 'unpredictable', 'twists', 'that', 'link', 'various', 'parts', 'of', 'the', 'story', 'together', 'by', 'the', 'final', 'episode', 'all', 'loose', 'ends', 'are', 'neatly', 'tied', 'up', 'and', 'what', 'left', 'is', 'hugely', 'satisfying', 'epilogue', 'the', 'animation', 'in', 'fma', 'brotherhood', 'is', 'crisp', 'and', 'very', 'well', 'done', 'although', 'it', 'does', 'sometimes', 'dip', 'bit', 'in', 'quality', 'compared', 'to', 'the', 'original', 'fma', 'it', 'bit', 'simpler', 'but', 'that', 'just', 'because', 'the', 'original', 'set', 'very', 'high', 'standard', 'to', 'follow', 'the', 'facial', 'emotions', 'of', 'the', 'characters', 'are', 'also', 'perfectly', 'presented', 'the', 'action', 'scenes', 'are', 'brilliant', 'and', 'very', 'well', 'animated', 'with', 'variety', 'of', 'alchemy', 'techniques', 'and', 'other', 'talents', 'being', 'displayed', 'nearly', 'every', 'episode', 'the', 'various', 'battles', 'are', 'consistently', 'exciting', 'to', 'watch', 'but', 'somehow', 'get', 'even', 'better', 'towards', 'the', 'end', 'of', 'the', 'series', 'the', 'voice', 'acting', 'is', 'of', 'an', 'excellent', 'and', 'consistent', 'quality', 'and', 'think', 'that', 'pretty', 'much', 'all', 'the', 'characters', 'have', 'voice', 'actors', 'which', 'suit', 'their', 'personalities', 'the', 'majority', 'of', 'the', 'openings', 'endings', 'are', 'pleasure', 'to', 'watch', 'due', 'to', 'fantastic', 'animated', 'sequences', 'and', 'theme', 'songs', 'the', 'background', 'music', 'which', 'play', 'during', 'the', 'episodes', 'usually', 'fit', 'very', 'well', 'with', 'the', 'situation', 'although', 'some', 'tracks', 'seem', 'to', 'be', 'overused', 'little', 'at', 'first', 'this', 'becomes', 'less', 'of', 'problem', 'as', 'the', 'series', 'progresses', 'with', 'plenty', 'of', 'new', 'music', 'being', 'introduced', 'to', 'support', 'the', 'story', 'as', 'it', 'reaches', 'the', 'finale', 'moving', 'on', 'to', 'the', 'characters', 'best', 'thing', 'about', 'this', 'series', 'the', 'original', 'fma', 'focussed', 'mainly', 'on', 'ed', 'and', 'al', 'and', 'on', 'their', 'struggles', 'to', 'regain', 'their', 'bodies', 'whereas', 'brotherhood', 'also', 'explores', 'other', 'characters', 'to', 'great', 'detail', 'at', 'the', 'same', 'time', 'the', 'majority', 'of', 'the', 'spotlight', 'is', 'still', 'on', 'the', 'two', 'brothers', 'but', 'it', 'highlights', 'their', 'interactions', 'with', 'new', 'characters', 'which', 'were', 'not', 'present', 'in', 'the', 'original', 'anime', 'new', 'characters', 'include', 'group', 'of', 'people', 'from', 'xing', 'neighbouring', 'country', 'another', 'person', 'from', 'the', 'armstrong', 'family', 'who', 'think', 'has', 'become', 'one', 'of', 'the', 'coolest', 'members', 'of', 'the', 'supporting', 'cast', 'and', 'new', 'main', 'antagonist', 'for', 'me', 'the', 'xingese', 'characters', 'in', 'particular', 'ling', 'yao', 'and', 'mei', 'chang', 'among', 'others', 'provide', 'new', 'dimension', 'to', 'the', 'fma', 'world', 'by', 'showing', 'us', 'different', 'culture', 'to', 'the', 'militaristic', 'one', 'we', 're', 'familiar', 'with', 'think', 'the', 'new', 'antagonist', 'is', 'an', 'improvement', 'on', 'the', 'original', 'fma', 'as', 'this', 'person', 'has', 'much', 'stronger', 'and', 'clever', 'link', 'to', 'the', 'elric', 'brothers', 'father', 'returning', 'characters', 'from', 'the', 'original', 'fma', 'such', 'as', 'mustang', 'and', 'scar', 'are', 'much', 'more', 'awesome', 'and', 'developed', 'due', 'to', 'the', 'fact', 'that', 'brotherhood', 'is', 'faithful', 'to', 'the', 'manga', 'plus', 'winry', 'rockbell', 'now', 'has', 'much', 'more', 'active', 'role', 'in', 'the', 'story', 'can', 'say', 'for', 'sure', 'that', 'this', 'anime', 'has', 'one', 'of', 'the', 'best', 'main', 'supporting', 'casts', 've', 'ever', 'seen', 'and', 'you', 'probably', 'find', 'it', 'difficult', 'to', 'label', 'any', 'of', 'the', 'recurring', 'characters', 'whether', 'they', 'are', 'good', 'or', 'evil', 'as', 'being', 'either', 'boring', 'or', 'unnecessary', 'in', 'terms', 'of', 'the', 'storyline', 'one', 'of', 'the', 'many', 'good', 'things', 'about', 'this', 'series', 'is', 'that', 'there', 'has', 'been', 'absolutely', 'no', 'filler', 'at', 'all', 'yes', 'thinking', 'of', 'naruto', 'inuyasha', 'etc', 'which', 'prevents', 'the', 'story', 'from', 'losing', 'momentum', 'all', 'the', 'episodes', 'are', 'concise', 'and', 'every', 'scene', 'is', 'important', 'as', 'part', 'of', 'the', 'huge', 'plot', 'the', 'dialogue', 'fully', 'explains', 'everything', 'and', 'is', 'straight', 'to', 'the', 'point', 'as', 'multiple', 'characters', 'are', 'explored', 'there', 'are', 'lots', 'of', 'side', 'stories', 'but', 'these', 'are', 'all', 'perfectly', 'intertwined', 'with', 'the', 'main', 'story', 'of', 'the', 'elric', 'brothers', 'and', 'more', 'often', 'than', 'not', 'directly', 'influence', 'their', 'journey', 'too', 'like', 'most', 'anime', 'series', 'there', 'are', 'things', 'from', 'the', 'manga', 'which', 'have', 'been', 'left', 'out', 'but', 'these', 'are', 'usually', 'just', 'restricted', 'to', 'comedy', 'moments', 'there', 'has', 'been', 'one', 'episode', 'which', 'shows', 'lot', 'of', 'flashbacks', 'of', 'events', 'so', 'far', 'but', 'that', 'forgiven', 'as', 'it', 'shows', 'the', 'most', 'epic', 'moments', 'of', 'the', 'series', 'and', 'also', 'provided', 'us', 'with', 'some', 'history', 'on', 'the', 'father', 'of', 'the', 'elric', 'brothers', 'fma', 'brotherhood', 'will', 'be', 'sorely', 'missed', 'now', 'that', 'it', 'finished', 'it', 'is', 'excellent', 'in', 'every', 'aspect', 'and', 'has', 'very', 'little', 'if', 'anything', 'that', 'can', 'be', 'called', 'flaw', 'maybe', 'rushed', 'character', 'development', 'at', 'first', 'due', 'to', 'the', 'fast', 'pacing', 'but', 'this', 'quickly', 'subsides', 'each', 'episode', 'feels', 'like', 'it', 'too', 'short', 'testimony', 'to', 'how', 'much', 'it', 'draws', 'you', 'in', 'to', 'the', 'story', 'and', 'characters', 'there', 'are', 'moments', 'which', 'leave', 'you', 'smiling', 'laughing', 'sad', 'and', 'simply', 'amazed', 'try', 'this', 'anime', 'it', 'recommended', 'for', 'absolutely', 'everyone', 'to', 'newcomers', 'and', 'to', 'those', 'familiar', 'with', 'fullmetal', 'alchemist', 'helpful', 'read', 'more']\n"
     ]
    }
   ],
   "source": [
    "# Clean and tokenize the reviews\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overall', 'story', 'animation', 'sound', 'character', 'enjoyment', 'spoiler', 'warning', 'aside', 'from', 'the', 'usual', 'everyday', 'anime', 'art', 'and', 'sound', 'standard', 'of', 'which', 'most', 'animes', 'pass', 'anyways', 'there', 'are', 'essentially', 'three', 'main', 'factors', 'that', 'see', 'as', 'important', 'in', 'anime', 'complexity', 'detail', 'which', 'adds', 'depth', 'characters', 'plot', 'setting', 'progress', 'which', 'adds', 'depth', 'character', 'development', 'plot', 'development', 'shifts', 'of', 'setting', 'novelty', 'which', 'again', 'adds', 'depth', 'characters', 'personality', 'setting', 'plot', 'complexity', 'detail', 'it', 'understandable', 'that', 'because', 'fma', 'brotherhood', 'paid', 'attention', 'to', 'its', 'simple', 'minded', 'viewers', 'readers', 'the', 'resulting', 'complexity', 'of', 'the', 'entirety', 'of', 'the', 'anime', 'would', 'turn', 'out', 'bland', 'the', 'characters', 'were', 'too', 'simple', 'particular', 'the', 'main', 'characters', 'the', 'plot', 'was', 'horrendously', 'predictable', 'after', 'episodes', 'and', 'then', 'there', 'was', 'the', 'lack', 'of', 'focus', 'in', 'the', 'setting', 'we', 'see', 'an', 'icy', 'place', 'dessert', 'place', 'and', 'then', 'there', 'the', 'ordinary', 'regions', 'where', 'the', 'main', 'characters', 'dwell', 'character', 'edward', 'elric', 'supposed', 'talented', 'alchemist', 'or', 'close', 'with', 'terrible', 'past', 'he', 'is', 'strong', 'willed', 'but', 'at', 'the', 'same', 'time', 'childish', 'he', 'gets', 'very', 'attached', 'to', 'acquainted', 'war', 'victims', 'and', 'is', 'always', 'affected', 'by', 'the', 'past', 'he', 'uses', 'automail', 'right', 'arm', 'and', 'left_leg', 'and', 'alchemy', 'to', 'fight', 'his', 'way', 'through', 'almost', 'everything', 'at', 'first', 'he', 'hates', 'his', 'father', 'he', 'wants', 'to', 'bring', 'back', 'his', 'and', 'his', 'brother', 'bodies', 'that', 'it', 'no', 'deep', 'personal', 'philosophy', 'no', 'internal', 'struggle', 'no', 'moral', 'ambiguity', 'no', 'split', 'demonic', 'personality', 'no', 'subconscious', 'complications', 'no', 'crazy', 'stuff', 'no', 'bullshit', 'he', 'just', 'does', 'what', 'he', 'feels', 'is', 'right', 'true', 'ed', 'experiences', 'things', 'such', 'as', 'guilt', 'and', 'sorrow', 'because', 'of', 'the', 'things', 'he', 'feels', 'as', 'mistakes', 'he', 'consistently', 'feels', 'regretful', 'for', 'trying', 'to', 'transmute', 'her', 'own', 'mother', 'and', 'his', 'own', 'dad', 'accused', 'him', 'for', 'actually', 'just', 'being', 'coward', 'nevertheless', 'said', 'reaction', 'and', 'thoughts', 'are', 'way', 'too', 'simple', 'in', 'the', 'end', 'the', 'show', 'just', 'forces', 'the', 'viewer', 'and', 'edward', 'to', 'just', 'swallow', 'everything', 'and', 'move', 'on', 'alphonse', 'elric', 'actually', 'preferred', 'this', 'guy', 'over', 'his', 'brother', 'mean', 'think', 'about', 'the', 'psychology', 'of', 'character', 'stuck', 'on', 'an', 'empty', 'armor', 'think', 'about', 'its', 'implications', 'also', 'liked', 'the', 'idea', 'that', 'alphonse', 'is', 'naive', 'yet', 'inhumanely', 'able', 'he', 'doesn', 'have', 'to', 'eat', 'or', 'sleep', 'and', 'is', 'almost', 'immortal', 'though', 'arguable', 'since', 'it', 'was', 'mentioned', 'that', 'there', 'is', 'possibility', 'that', 'the', 'armor', 'would', 'reject', 'his', 'soul', 'eventually', 'link', 'naive', 'to', 'his', 'actual', 'physicality', 'his', 'main', 'vulnerability', 'is', 'still', 'an', 'internal', 'idea', 'the', 'seal', 'transcribed', 'within', 'his', 'metal', 'body', 'the', 'only', 'problem', 'with', 'the', 'character', 'is', 'the', 'lack', 'of', 'focus', 'on', 'his', 'own', 'thoughts', 'and', 'so', 'on', 'the', 'lack', 'of', 'exploration', 'in', 'his', 'psychology', 'there', 'was', 'one', 'episode', 'that', 'showed', 'al', 'doubt', 'of', 'his', 'own', 'existence', 'but', 'this', 'wasn', 'clearly', 'detailed', 'enough', 'plot', 'not', 'much', 'to', 'say', 'here', 'mother', 'dies', 'they', 'become', 'state', 'alchemist', 'look', 'for', 'philosopher_stone', 'how', 'are', 'they', 'even', 'allowed', 'the', 'time', 'they', 'meet', 'homunculus', 'they', 'save', 'everyone', 'from', 'homunculus', 'at', 'the', 'same', 'time', 'they', 'get', 'their', 'bodies_back', 'that', 'it', 'they', 'should', 've', 'at', 'least', 'included', 'lin', 'chinese', 'struggle', 'and', 'absorbed', 'the', 'surrounding', 'nations', 'within', 'the', 'plot', 'setting', 'automails', 'interesting', 'idea', 'problem', 'detail', 'no', 'elaboration', 'how', 'many', 'nations', 'were', 'there', 'only', 'remember', 'desert', 'snow', 'and', 'the', 'rest', 'of', 'the', 'dullness', 'where', 'is', 'the', 'economy', 'alchemy', 'the', 'main', 'idea', 'of', 'the', 'show', 'quite', 'elaborate', 'in', 'terms', 'of', 'the', 'gate', 'immortality', 'and', 'other', 'plot', 'devices', 'problem', 'how', 'much', 'variety', 'of', 'alchemy', 'did', 'ed', 'and', 'al', 'actually', 'use', 'move', 'rocks', 'and', 'move', 'more', 'rocks', 'mustang', 'did', 'fire', 'tricks', 'where', 'are', 'the', 'complicated', 'algorithms', 'the', 'super', 'moves', 'the', 'classification', 'of', 'alchemy', 'there', 'were', 'mentions', 'of', 'eastern', 'alchemy', 'western', 'alchemy', 'comprehension', 'deconstruction', 'reconstruction', 'equal', 'exchange', 'but', 'these', 'things', 'weren', 'sufficiently', 'fused', 'and', 'utilized', 'as', 'basis', 'for', 'unique', 'battle', 'system', 'sigh', 'progress', 'ok', 'what', 'happened', 'again', 'they', 'walk', 'everywhere', 'and', 'found', 'out', 'that', 'what', 'they', 'were', 'looking', 'for', 'was', 'right', 'beneath', 'their', 'city', 'and', 'that', 'it', 'sourced', 'out', 'of', 'human', 'souls', 'how', 'did', 'they', 'change', 'physically', 'and', 'mentally', 'character', 'development', 'how', 'much', 'did', 'ed', 'grow', 'how', 'much', 'did', 'his', 'personality', 'go', 'from', 'to', 'how', 'much', 'did', 'his', 'height', 'go', 'from', 'to', 'ask', 'yourself', 'how', 'much', 'did', 'al', 'grow', 'after', 'experiencing', 'all', 'those', 'moments', 'you', 'think', 'they', 'have', 'more', 'bad', 'ass', 'versions', 'of', 'themselves', 'mean', 'at', 'least', 'change', 'the', 'character', 'appearances', 'transmute', 'al', 'armor', 'into', 'some', 'flexible', 'form', 'or', 'cut', 'ed', 'hair', 'plot', 'development', 'when', 'said', 'already', 'knew', 'the', 'outcome', 'after', 'episodes', 'wasn', 'kidding', 'maybe', 'that', 'exactly', 'why', 'felt', 'there', 'wasn', 'much', 'change', 'these', 'homunculus', 'just', 'won', 'die', 'they', 'keep', 'coming', 'back', 'and', 'it', 'like', 'show', 'of', 'power', 'puff', 'girls', 'where', 'the', 'girls', 'continuously', 'fight', 'their', 'arch', 'nemesis', 'and', 'don', 'even', 'get', 'me', 'started', 'on', 'the', 'shallowness', 'of', 'the', 'homunculus', 'though', 'particularly', 'liked', 'envy', 'and', 'his', 'end', 'almost', 'nothing', 'aside', 'from', 'what', 'was', 'already', 'known', 'was', 'happening', 'they', 'found', 'out', 'about', 'city', 'secret', 'and', 'they', 'go', 'back', 'to', 'their', 'traveling', 'and', 'meeting', 'new', 'friends', 'and', 'then', 'they', 'go', 'back', 'traveling', 'and', 'finally', 'they', 'decided', 'to', 'finish', 'the', 'job', 'shift', 'of', 'setting', 'guess', 'shouldn', 'have', 'expected', 'one', 'piece', 'there', 'were', 'some', 'interesting', 'places', 'such', 'as', 'the', 'destroyed', 'kingdom', 'or', 'the', 'northern', 'camp', 'but', 'almost', 'everything', 'happened', 'in', 'the', 'same', 'region', 'novelty', 'alchemy', 'and', 'automail', 'shounen', 'is', 'an', 'interesting', 'combination', 'if', 'hadn', 'watched', 'the', 'first', 'anime', 'it', 'wouldn', 'better', 'not', 'really', 'they', 'give', 'you', 'interesting', 'general', 'ideas', 'and', 'they', 'stop', 'there', 'more', 'details', 'would', 'have', 'produced', 'more', 'novelty', 'character', 'wise', 'the', 'two', 'had', 'too', 'normal', 'personalities', 'interestingly', 'enough', 'the', 'flashbacks', 'had', 'more', 'novel', 'point', 'of', 'view', 'than', 'the', 'original', 'characters', 'what', 'would', 'have', 'really', 'gotten', 'well', 'was', 'if', 'their', 'circumstances', 'actually', 'shaped', 'plenty', 'of', 'their', 'personalities', 'the', 'loss', 'body', 'parts', 'didn', 'serve', 'much', 'meaning', 'in', 'terms', 'of', 'their', 'character', 'build', 'up', 'what', 'saw', 'was', 'stubborn', 'kid', 'and', 'naive', 'brother', 'how', 'swell', 'setting', 'good', 'general', 'idea', 'not', 'detailed', 'meaningless', 'plot', 'novel', 'in', 'general', 'but', 'the', 'lack', 'of', 'detail', 'lessens', 'the', 'entire', 'novelty', 'clearly', 'not', 'for', 'cpn', 'character', 'progress', 'novelty', 'oriented', 'individuals', 'helpful_read', 'more']\n"
     ]
    }
   ],
   "source": [
    "# Create bigrams, remove stop words and lemmatize the reviews\n",
    "\n",
    "# Build the bigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_mod[data_words[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining removing stopwords\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "# Defining making bigrams\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# Defining lemmatization\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overall', 'story', 'animation', 'sound', 'character', 'enjoyment', 'first', 'see', 'original', 'fma', 'popular', 'original', 'pacing', 'conclusion', 'sit', 'well', 'brotherhood', 'mean', 'remake', 'original', 'time', 'stick', 'manga', 'way', 'people', 'think', 'spoil', 'franchise', 'myth', 'dispel', 'word', 'describe', 'series', 'epic', 'admit', 'see', 'original', 'read', 'manga', 'pace', 'brotherhood', 'seem', 'start', 'fast', 'finally', 'get', 'use', 'pace', 'watch', 'first', 'ep', 'event', 'take', 'half', 'volume', 'manga', 'spread', 'episode', 'original', 'anime', 'show', 'single', 'episode', 'however', 'try', 'look', 'perspective', 'new', 'fma', 'compare', 'manga', 'original', 'believe', 'pace', 'work', 'manage', 'tell', 'intriguing', 'story', 'effectively', 'little', 'confusion', 'plot', 'full', 'clever', 'idea', 'unpredictable', 'twist', 'link', 'various', 'part', 'story', 'together', 'final', 'episode', 'loose_end', 'neatly', 'tie', 'leave', 'hugely', 'satisfy', 'epilogue', 'animation', 'fma', 'brotherhood', 'crisp', 'well', 'do', 'sometimes', 'dip', 'bit', 'quality', 'compare', 'original', 'fma', 'bit', 'simple', 'original', 'set', 'high', 'standard', 'follow', 'facial', 'emotion', 'character', 'also', 'perfectly', 'present', 'action', 'scene', 'brilliant', 'well', 'animate', 'variety', 'alchemy', 'technique', 'talent', 'display', 'nearly', 'episode', 'various', 'battle', 'consistently', 'exciting', 'watch', 'somehow', 'get', 'even', 'well', 'end', 'series', 'voice_acte', 'excellent', 'consistent', 'quality', 'think', 'pretty', 'much', 'character', 'voice_actor', 'suit', 'personalitie', 'majority', 'opening', 'ending', 'pleasure', 'watch', 'due', 'fantastic', 'animated', 'sequence', 'theme_song', 'background', 'music', 'play', 'episode', 'usually', 'fit', 'well', 'situation', 'track', 'seem', 'overused', 'little', 'first', 'become', 'less', 'problem', 'series', 'progress', 'plenty', 'new', 'music', 'introduce', 'support', 'story', 'reach', 'finale', 'move', 'character', 'good', 'thing', 'series', 'original', 'fma', 'focusse', 'mainly', 'struggle', 'regain', 'body', 'brotherhood', 'also', 'explore', 'character', 'great', 'detail', 'time', 'majority', 'spotlight', 'still', 'brother', 'highlight', 'interaction', 'new', 'character', 'present', 'original', 'anime', 'new', 'character', 'include', 'group', 'people', 'xe', 'neighbouring', 'country', 'person', 'armstrong', 'family', 'think', 'become', 'cool', 'member', 'new', 'main', 'antagonist', 'xingese', 'character', 'particular', 'mei', 'chang', 'other', 'provide', 'new', 'dimension', 'fma', 'world', 'show', 'different', 'culture', 'militaristic', 'familiar', 'think', 'new', 'antagonist', 'improvement', 'original', 'fma', 'person', 'much', 'strong', 'clever', 'link', 'father', 'return', 'character', 'original', 'fma', 'mustang', 'scar', 'much', 'awesome', 'develop', 'due', 'fact', 'brotherhood', 'faithful', 'manga', 'much', 'active', 'role', 'story', 'say', 'sure', 'anime', 'good', 'main', 'support', 'cast', 'ever', 'see', 'probably', 'find', 'difficult', 'label', 'recur', 'character', 'good', 'evil', 'boring', 'unnecessary', 'term', 'storyline', 'many', 'good', 'thing', 'series', 'absolutely', 'filler', 'yes', 'think', 'naruto', 'inuyasha', 'prevent', 'story', 'lose', 'momentum', 'episode', 'concise', 'scene', 'important', 'part', 'huge', 'plot', 'dialogue', 'fully', 'explain', 'straight', 'point', 'multiple', 'character', 'explore', 'lot', 'side', 'story', 'perfectly', 'intertwine', 'main', 'story', 'elric_brother', 'often', 'directly', 'influence', 'journey', 'anime', 'series', 'thing', 'manga', 'leave', 'usually', 'restrict', 'comedy', 'moment', 'episode', 'show', 'lot', 'flashback', 'event', 'far', 'forgive', 'show', 'epic', 'moment', 'series', 'also', 'provide', 'history', 'father', 'elric_brother', 'fma', 'brotherhood', 'sorely', 'miss', 'finished', 'excellent', 'aspect', 'little', 'call', 'flaw', 'maybe', 'rush', 'character', 'development', 'first', 'due', 'fast', 'pacing', 'quickly', 'subside', 'episode', 'feel', 'short', 'testimony', 'much', 'draw', 'story', 'character', 'moment', 'leave', 'smile', 'laugh', 'sad', 'simply', 'amazed', 'try', 'anime', 'recommend', 'absolutely', 'newcomer', 'familiar', 'fullmetal_alchemist', 'helpful_read']\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 2), (10, 5), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 6), (25, 1), (26, 1), (27, 1), (28, 13), (29, 2), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 3), (56, 1), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 8), (66, 1), (67, 2), (68, 1), (69, 1), (70, 2), (71, 1), (72, 1), (73, 2), (74, 1), (75, 1), (76, 1), (77, 2), (78, 1), (79, 1), (80, 1), (81, 2), (82, 2), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 4), (91, 1), (92, 1), (93, 1), (94, 9), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 2), (103, 4), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 3), (128, 1), (129, 2), (130, 3), (131, 1), (132, 1), (133, 1), (134, 2), (135, 3), (136, 1), (137, 2), (138, 1), (139, 6), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 3), (148, 1), (149, 1), (150, 5), (151, 1), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 7), (160, 1), (161, 1), (162, 1), (163, 12), (164, 1), (165, 1), (166, 1), (167, 3), (168, 2), (169, 2), (170, 1), (171, 2), (172, 2), (173, 2), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 2), (180, 1), (181, 1), (182, 2), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 2), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 2), (206, 3), (207, 2), (208, 1), (209, 7), (210, 1), (211, 1), (212, 4), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 9), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 2), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 3), (248, 5), (249, 1), (250, 2), (251, 1), (252, 1), (253, 2), (254, 1), (255, 1), (256, 1), (257, 1), (258, 2), (259, 1), (260, 2), (261, 1), (262, 1), (263, 1), (264, 3), (265, 1), (266, 5), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.001*\"disjoint\" + 0.001*\"stylistic\" + 0.001*\"exquisitely\" + 0.000*\"bane\" + 0.000*\"antic\" + 0.000*\"reconciliation\" + 0.000*\"commentate\" + 0.000*\"endpoint\" + 0.000*\"pretentiously\" + 0.000*\"sugarcoat\"'), (1, '0.011*\"alchemy\" + 0.010*\"edward\" + 0.009*\"get\" + 0.009*\"make\" + 0.009*\"brother\" + 0.008*\"human\" + 0.007*\"show\" + 0.006*\"fight\" + 0.006*\"body\" + 0.006*\"alphonse\"'), (2, '0.000*\"grader\" + 0.000*\"prayer\" + 0.000*\"righ\" + 0.000*\"yaaay\" + 0.000*\"implore\" + 0.000*\"oozed\" + 0.000*\"cave\" + 0.000*\"conclusive\" + 0.000*\"alche\" + 0.000*\"appreciation\"'), (3, '0.032*\"character\" + 0.027*\"anime\" + 0.024*\"story\" + 0.016*\"watch\" + 0.014*\"show\" + 0.013*\"good\" + 0.013*\"well\" + 0.012*\"brotherhood\" + 0.011*\"series\" + 0.011*\"sound\"'), (4, '0.000*\"grader\" + 0.000*\"prayer\" + 0.000*\"righ\" + 0.000*\"yaaay\" + 0.000*\"implore\" + 0.000*\"oozed\" + 0.000*\"cave\" + 0.000*\"conclusive\" + 0.000*\"alche\" + 0.000*\"appreciation\"'), (5, '0.025*\"el\" + 0.018*\"s\" + 0.008*\"fuck\" + 0.007*\"ve\" + 0.007*\"hagaren\" + 0.007*\"aswell\" + 0.006*\"be\" + 0.005*\"en\" + 0.005*\"sometime\" + 0.005*\"fly\"'), (6, '0.012*\"pero\" + 0.012*\"por\" + 0.012*\"son\" + 0.011*\"todo\" + 0.008*\"los\" + 0.007*\"ubermensch\" + 0.007*\"tiene\" + 0.006*\"para\" + 0.005*\"musical\" + 0.005*\"muy\"'), (7, '0.032*\"que\" + 0.012*\"una\" + 0.008*\"un\" + 0.007*\"tant\" + 0.007*\"personaje\" + 0.005*\"qui\" + 0.005*\"je\" + 0.005*\"apartado\" + 0.005*\"tan\" + 0.005*\"esta\"')]\n"
     ]
    }
   ],
   "source": [
    "# Using LDA to develop a topic model with 3 models\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "# Print the KeywordS in the 3 topics\n",
    "print(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1952819382909622087422772407\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1952819382909622087422772407_data = {\"mdsDat\": {\"x\": [-0.3312198894731042, -0.2727890593792462, 0.15439833894307542, 0.10853009122249316, 0.10521856153816327, 0.07912759134267941, 0.07836718290296937, 0.0783671829029694], \"y\": [-0.15250884977732287, 0.17145505529288732, -0.0316424101221812, 0.0026581498769495068, 0.0024420200961876313, 0.002524339963457289, 0.0025358473350111928, 0.0025358473350111945], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [80.13073042635075, 18.84971794892741, 0.44599388108004884, 0.3392143689349713, 0.2038418150268019, 0.020376222497030073, 0.005207423188349467, 0.004917913994638867]}, \"tinfo\": {\"Term\": [\"anime\", \"alchemy\", \"edward\", \"watch\", \"brother\", \"make\", \"brotherhood\", \"get\", \"human\", \"overall\", \"series\", \"sound\", \"animation\", \"enjoyment\", \"story\", \"fight\", \"want\", \"fma\", \"alphonse\", \"body\", \"lose\", \"s\", \"world\", \"original\", \"people\", \"elric\", \"homunculus\", \"art\", \"father\", \"life\", \"watch\", \"anime\", \"enjoyment\", \"fma\", \"original\", \"overall\", \"manga\", \"favorite\", \"enjoy\", \"art\", \"version\", \"opinion\", \"soundtrack\", \"pretty\", \"style\", \"definitely\", \"recommend\", \"brotherhood\", \"top\", \"animation\", \"adaptation\", \"fan\", \"music\", \"dub\", \"read\", \"compare\", \"worth\", \"sound\", \"deserve\", \"job\", \"series\", \"story\", \"first\", \"fullmetal_alchemist\", \"much\", \"episode\", \"amazing\", \"character\", \"well\", \"really\", \"love\", \"great\", \"good\", \"review\", \"see\", \"say\", \"show\", \"time\", \"ever\", \"feel\", \"end\", \"get\", \"make\", \"also\", \"even\", \"truth\", \"kill\", \"pride\", \"humanity\", \"lust\", \"roy\", \"bradley\", \"woman\", \"revenge\", \"kimblee\", \"human_transmutation\", \"government\", \"destroy\", \"obtain\", \"soldier\", \"gluttony\", \"nation\", \"dude\", \"limb\", \"riza_hawkeye\", \"represent\", \"automail\", \"protect\", \"state_alchemist\", \"soul\", \"depict\", \"sloth\", \"flask\", \"bind\", \"join\", \"sin\", \"hohenheim\", \"human\", \"homunculus\", \"arm\", \"envy\", \"god\", \"father\", \"death\", \"greed\", \"law\", \"power\", \"powerful\", \"sacrifice\", \"armor\", \"scar\", \"amestris\", \"alchemy\", \"body\", \"mother\", \"military\", \"leg\", \"edward\", \"die\", \"lose\", \"brother\", \"fight\", \"elric\", \"alphonse\", \"world\", \"want\", \"make\", \"get\", \"ed\", \"life\", \"people\", \"show\", \"even\", \"way\", \"go\", \"character\", \"thing\", \"que\", \"una\", \"tant\", \"personaje\", \"je\", \"qui\", \"apartado\", \"esta\", \"tan\", \"et\", \"dan\", \"cantidad\", \"como\", \"crear\", \"del\", \"nada\", \"nombrar\", \"sus\", \"tambien\", \"tengo\", \"mon\", \"cet\", \"sont\", \"sur\", \"une\", \"algo\", \"asi\", \"detalle\", \"es\", \"forma\", \"un\", \"la\", \"importance\", \"el\", \"ve\", \"hagaren\", \"aswell\", \"be\", \"en\", \"sometime\", \"fly\", \"villian\", \"everytime\", \"hence\", \"originality\", \"wanting\", \"fab\", \"wtf\", \"realy\", \"trisha_lullaby\", \"bitch\", \"kiss\", \"pump\", \"america\", \"basicly\", \"generate\", \"retarded\", \"obsess\", \"echange\", \"hypothetically\", \"ight\", \"sorceror\", \"shippuden\", \"s\", \"fuck\", \"m\", \"stone\", \"fav\", \"ill\", \"un\", \"pero\", \"por\", \"todo\", \"los\", \"ubermensch\", \"tiene\", \"para\", \"muy\", \"su\", \"lullaby\", \"tank\", \"nietzsche\", \"desde\", \"tienen\", \"christian\", \"hasta\", \"hermano\", \"llevar\", \"pena\", \"quien\", \"sentido\", \"ver\", \"symbolic\", \"humble\", \"federal\", \"uno\", \"overman\", \"vain\", \"spiritual\", \"smartly\", \"musical\", \"son\", \"solo\", \"la\", \"disjoint\", \"stylistic\", \"exquisitely\", \"bane\", \"antic\", \"commentate\", \"reconciliation\", \"endpoint\", \"pretentiously\", \"horrifically\", \"introspective\", \"sugarcoat\", \"ghoul\", \"mistranslation\", \"sophisticatedly\", \"powerfully\", \"provocative\", \"hunter\", \"chain\", \"zany\", \"minuet\", \"strech\", \"compelet\", \"yard\", \"blance\", \"renew\", \"yagami\", \"serene\", \"predictability\", \"panicked\", \"neuter\", \"undercut\", \"detracting\", \"doing\", \"exposit\", \"fansub\", \"reprising\", \"substantially\", \"tokyo\", \"unfocused\", \"powerfully\", \"provocative\", \"ghoul\", \"mistranslation\", \"sophisticatedly\", \"horrifically\", \"introspective\", \"sugarcoat\", \"endpoint\", \"pretentiously\", \"antic\", \"commentate\", \"reconciliation\", \"bane\", \"minuet\", \"strech\", \"compelet\", \"yard\", \"blance\", \"renew\", \"yagami\", \"serene\", \"predictability\", \"panicked\", \"certaninly\", \"descendant\", \"sneak\", \"wooow\", \"treck\", \"fyi\", \"absolutely\", \"action\", \"active\", \"admit\", \"alchemy\", \"also\", \"amazed\", \"animate\", \"animated\", \"animation\", \"anime\", \"antagonist\", \"armstrong\", \"aspect\", \"awesome\", \"background\", \"battle\", \"become\", \"believe\", \"bit\", \"body\", \"boring\", \"brilliant\", \"brother\", \"brotherhood\", \"call\", \"cast\", \"chang\", \"character\", \"clever\", \"powerfully\", \"provocative\", \"ghoul\", \"mistranslation\", \"sophisticatedly\", \"horrifically\", \"introspective\", \"sugarcoat\", \"endpoint\", \"pretentiously\", \"antic\", \"commentate\", \"reconciliation\", \"bane\", \"minuet\", \"strech\", \"compelet\", \"yard\", \"blance\", \"renew\", \"yagami\", \"serene\", \"predictability\", \"panicked\", \"certaninly\", \"descendant\", \"sneak\", \"wooow\", \"treck\", \"fyi\", \"absolutely\", \"action\", \"active\", \"admit\", \"alchemy\", \"also\", \"amazed\", \"animate\", \"animated\", \"animation\", \"anime\", \"antagonist\", \"armstrong\", \"aspect\", \"awesome\", \"background\", \"battle\", \"become\", \"believe\", \"bit\", \"body\", \"boring\", \"brilliant\", \"brother\", \"brotherhood\", \"call\", \"cast\", \"chang\", \"character\", \"clever\"], \"Freq\": [3653.0, 488.0, 517.0, 2087.0, 465.0, 1290.0, 1641.0, 1425.0, 265.0, 1430.0, 1517.0, 1484.0, 1424.0, 1185.0, 3196.0, 341.0, 521.0, 1018.0, 334.0, 249.0, 277.0, 65.0, 384.0, 833.0, 553.0, 274.0, 184.0, 714.0, 181.0, 324.0, 2087.3097135490452, 3652.53684070948, 1185.6451340619067, 1018.2095759750289, 833.0180832637191, 1430.057806138411, 537.6384795753827, 307.0269020245858, 424.3568851481668, 713.9819430153715, 223.73704713013464, 219.5120800096136, 250.79478085363135, 309.17444296849305, 206.54523606838774, 200.82140630376676, 195.34324274998244, 1639.4429703678074, 185.10913197822399, 1421.9644520143904, 175.74599412801166, 182.9691066651651, 310.60929048772715, 169.55211844896496, 161.29314036065838, 175.05768371273683, 153.63156934307963, 1481.7953466573545, 146.56211489004147, 141.3185074841005, 1515.0218417158205, 3158.700578060896, 1063.4739020882382, 843.2113326553372, 829.2898324329325, 1164.5656412093888, 440.25429606963905, 4245.886404397934, 1702.5865932614859, 1273.0709355301221, 655.5766219455015, 1108.9930438759257, 1726.5976489542381, 372.710963748137, 1076.2995828761382, 830.0394037977933, 1862.92913858248, 1095.0983073907037, 396.8753818790706, 852.6827702792651, 888.5746223548728, 1143.4104629977687, 1014.9621387947903, 764.6123361924444, 769.1505946411252, 136.5605594546435, 83.2768789136241, 64.73196851523491, 62.110797770671816, 57.237977168417125, 55.19003012865173, 45.29576723690837, 40.810505786547196, 39.53254522273586, 37.809510235462234, 35.894273288358825, 33.94690568168495, 33.64546021138802, 33.508280816454956, 33.508760323905825, 33.32438421850321, 32.401562978399525, 31.423927814045687, 30.68470485237278, 31.07714875764939, 29.572979638799872, 30.313300709138893, 29.17021900260513, 28.955870021160962, 115.97971898565841, 28.634380407345247, 27.285778513042864, 27.24108366015095, 35.20831408753573, 26.483264228217415, 85.31660111948031, 85.00543372712606, 254.4817931277854, 176.22485941550184, 92.18479497892912, 134.17868855059976, 146.02310824502894, 170.81133010605305, 106.81014558739196, 135.18862641154843, 73.64286411538733, 144.66975520056448, 73.63533841066223, 101.33161556563371, 65.52839744786898, 137.51292713859007, 55.12341885696531, 357.2649399733585, 194.7333199269005, 114.79676312327697, 104.18347697877385, 58.657597410519266, 315.01944042338357, 99.31485115162371, 182.59245481696746, 269.95616475326466, 197.91581453868287, 165.083975981278, 183.58857115017196, 164.60992979084142, 181.84562379241947, 275.6111901205651, 281.5800988689872, 137.74190475764797, 139.26009123362041, 159.63558538204236, 232.97224555624626, 159.73145758931847, 146.0618495187694, 145.77948917708952, 171.47136662163143, 134.47402121598867, 24.005862763678582, 9.186062089184208, 5.1583702363379516, 4.915285829739564, 3.7611482989162184, 3.7611482989162184, 3.695028409133471, 3.695028409133471, 3.695028409133471, 3.295404650766758, 2.9483022504872807, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.474701357282899, 2.363905576048372, 1.8981439138456129, 1.8981439138456129, 1.8981439138456129, 1.8981439138456129, 1.864462657327503, 1.864462657327503, 1.864462657327503, 1.864462657327503, 1.864462657327503, 5.993368373962116, 2.991046134722831, 1.9832998080271047, 14.11779846538888, 4.160522395791035, 3.893962189116285, 3.813093039858929, 3.6632918617526076, 3.071442291501479, 2.9175247105226205, 2.6364592096701256, 2.2919998398597143, 2.2665944963678823, 2.233312049869114, 2.116945084763166, 2.0579218802646775, 1.8693779551456646, 1.865694192196107, 1.7050969090202874, 1.691638830051971, 1.63854769329158, 1.4695711075392754, 1.442672076030775, 1.301634095974617, 1.287171354383694, 1.2858689553950906, 1.2050652817899028, 1.1580473081870706, 1.1417703508898904, 1.1417703508898904, 1.1417703508898904, 1.1417703508898904, 1.1313047858833507, 9.935818763015831, 4.641845376412927, 2.214893762088345, 2.0575598539223066, 1.3275291235692854, 1.3798233544544931, 1.244397177930354, 4.05306182323003, 4.05306182323003, 3.729246948825916, 2.743402538230395, 2.406289718419655, 2.214643472853756, 2.10717437596212, 1.6476093717125173, 1.6476093717125173, 1.617964930041882, 1.4738557478454655, 1.3171003204257103, 1.2958210269410504, 1.2958210269410504, 0.9278489526180171, 0.8365435561056479, 0.8365435561056479, 0.8365435561056479, 0.8365435561056479, 0.8365435561056479, 0.8365435561056479, 0.8365435561056479, 0.8306794419564048, 0.822042910360771, 0.7282969631620132, 0.7282969631620132, 0.7231197783726311, 0.7219607780466699, 0.712606204582425, 0.6980844213316033, 1.6921479175720207, 4.027103382596058, 1.2705545823350308, 1.1510305362196873, 0.03968687770142701, 0.030783534844550115, 0.02402271998429032, 0.012486985803614913, 0.012486984814417684, 0.012486984814417684, 0.012486984814417684, 0.012486982836023227, 0.012486982836023227, 0.012486981846825998, 0.012486981846825998, 0.012486981846825998, 0.01248698085762877, 0.01248698085762877, 0.01248698085762877, 0.01248697986843154, 0.01248697986843154, 0.01248593329776365, 0.012484638438591374, 0.011448079435852071, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.003522106718240114, 0.0036291744586753115, 0.003628619766329357, 0.0035528613546768274, 0.0035528613546768274, 0.0035528613546768274, 0.0035528613546768274, 0.0035528613546768274, 0.0035871879823061222, 0.0035584884031118875, 0.0035524713636694402, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0009064220327358709, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526, 0.0008560290643967526], \"Total\": [3653.0, 488.0, 517.0, 2087.0, 465.0, 1290.0, 1641.0, 1425.0, 265.0, 1430.0, 1517.0, 1484.0, 1424.0, 1185.0, 3196.0, 341.0, 521.0, 1018.0, 334.0, 249.0, 277.0, 65.0, 384.0, 833.0, 553.0, 274.0, 184.0, 714.0, 181.0, 324.0, 2087.5692455659405, 3653.009017156264, 1185.928014973707, 1018.4691888204919, 833.2791266938528, 1430.7089470027124, 537.897831279288, 307.2917735762913, 424.73500009938147, 714.700121052828, 223.99669304411228, 219.77147258701768, 251.10229836156634, 309.56292432825114, 206.8048376405318, 201.0807627801354, 195.60256134819227, 1641.7049338298089, 185.36919389096983, 1424.013016005501, 176.00554014248613, 183.23947791937604, 311.06844861684976, 169.81146092609885, 161.5530338306817, 175.3441474570249, 153.895801667548, 1484.3661141160344, 146.8217339653871, 141.578261310078, 1517.9389898909824, 3196.4990534205294, 1071.6922395888828, 848.2595897444106, 840.5724912399829, 1185.9561376892254, 444.1618965135549, 4417.467863890398, 1757.7221335802, 1308.352822798781, 665.1104460785847, 1139.6908422637093, 1819.0887543201748, 377.2829464179596, 1130.6038063344713, 869.937738013708, 2096.0114090438647, 1197.5942667719346, 403.85685049955737, 954.9282454035334, 1003.9319720973272, 1425.100612880391, 1290.6833946146658, 874.141860024994, 928.9921067294314, 136.8126638709592, 83.53191174448962, 64.9838936735251, 62.36322429718858, 57.49157707198949, 55.45261576427172, 45.547671876971066, 41.063287637617854, 39.78588510067597, 38.06151013360883, 36.14677987933526, 34.20023233709998, 33.89757401382196, 33.76020184540928, 33.76079098000193, 33.57631243242718, 32.6535813195373, 31.681060840721084, 30.94262539597366, 31.339588059629747, 29.824983514653763, 30.574813043544903, 29.422308941737906, 29.20783574486058, 116.9972350786873, 28.88701131829627, 27.537683602189986, 27.492973607890406, 35.5433288374402, 26.735563662817995, 86.47594479522469, 86.5762368555068, 265.7757836385795, 184.13381885704823, 95.23872576371674, 140.69690251449396, 153.85844418495006, 181.54623185296265, 114.0473708686644, 151.12741202931412, 79.0501174607732, 163.4269799218575, 79.12496439710065, 112.07125071325774, 70.34953915833248, 158.95741345069246, 58.23791466889563, 488.962870817085, 249.18606427077654, 136.3578140876285, 126.08504223845067, 63.67993281215922, 517.6118465454513, 125.72492097810589, 277.5651741317607, 465.9765957826914, 341.47050745394415, 274.30312729032613, 334.0401421273457, 384.3736783097088, 521.3435213457146, 1290.6833946146658, 1425.100612880391, 298.2063804200641, 324.7659476466605, 553.3749570454194, 2096.0114090438647, 928.9921067294314, 674.5906280067805, 868.2632947113335, 4417.467863890398, 786.7555895362265, 24.37124862618345, 9.551496020857277, 5.52368900121245, 5.2807288426713255, 4.126467603845335, 4.126467603845335, 4.060478363220786, 4.060478363220786, 4.060478363220786, 3.6607242339333776, 3.313808683540467, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.8401663563492128, 2.7292261308572345, 2.2634653634457256, 2.2634653634457256, 2.2634653634457256, 2.2634653634457256, 2.2299441603955485, 2.2299441603955485, 2.2299441603955485, 2.2299441603955485, 2.2299441603955485, 7.562057274073965, 4.4806008015661964, 15.067417401938458, 14.481234775103715, 4.520101091717215, 4.253408059664206, 4.171960334199639, 4.0222748997968125, 3.433420774921149, 3.277024147440393, 2.997985283761496, 2.65211258088409, 2.6269087791528127, 2.5930613340058195, 2.477834092664863, 2.417454405196464, 2.2285880984729607, 2.2254883631530027, 2.0642951808018255, 2.0541233267132473, 1.998567106518512, 1.8317121370147182, 1.8026272376432, 1.661675669949567, 1.6480086609861158, 1.646875695161597, 1.5646687359622145, 1.5209715282197658, 1.5010735658602135, 1.5010735658602135, 1.5010735658602135, 1.5010735658602135, 1.492591036693075, 65.29814030761978, 18.08395180925087, 12.025119115173354, 49.39081396107943, 6.45190988944407, 13.290680671847614, 7.562057274073965, 4.429033978500714, 4.429033978500714, 4.1038641137958, 3.118954788966964, 2.7806009181863107, 2.5900585496344655, 2.481896149681844, 2.022162747063696, 2.022162747063696, 1.9986204042732587, 1.8522182434756316, 1.6916486236005464, 1.6707534283703864, 1.6707534283703864, 1.302994056639512, 1.2111427499691902, 1.2111427499691902, 1.2111427499691902, 1.2111427499691902, 1.2111427499691902, 1.2111427499691902, 1.2111427499691902, 1.2054901130931277, 1.1993580368864742, 1.1024891990988872, 1.1024891990988872, 1.098122101907762, 1.0971908031073168, 1.0871351894247552, 1.0833385492680347, 4.118015767650986, 22.18707974480622, 3.9806737130228065, 4.4806008015661964, 0.43746519337457473, 0.4402663206210879, 0.4220156528265049, 0.41001786637284277, 0.41001786538364554, 0.41001786538364554, 0.41001786538364554, 0.4100178634052511, 0.4100178634052511, 0.41001786241605387, 0.41001786241605387, 0.41001786241605387, 0.41001786142685664, 0.41001786142685664, 0.41001786142685664, 0.4100178604376594, 0.4100178604376594, 0.426585014089698, 0.4522455430355006, 1.20758203167025, 0.4101517259523101, 0.4101853447824235, 0.41018807999357276, 0.4101936739187456, 0.4101969390385727, 0.41019720995985987, 0.41019932215069177, 0.41021062767742006, 0.4102119105674364, 0.4102127767176337, 0.4305037620203419, 0.43192406372067277, 0.41904744709862324, 0.41904744709862324, 0.41904744709862324, 0.41904744709862324, 0.41904744709862324, 1.2267996144604172, 1.5679373351828272, 1.7420101811234614, 0.4100178604376594, 0.4100178604376594, 0.41001786142685664, 0.41001786142685664, 0.41001786142685664, 0.41001786241605387, 0.41001786241605387, 0.41001786241605387, 0.4100178634052511, 0.4100178634052511, 0.41001786538364554, 0.41001786538364554, 0.41001786538364554, 0.41001786637284277, 0.4101517259523101, 0.4101853447824235, 0.41018807999357276, 0.4101936739187456, 0.4101969390385727, 0.41019720995985987, 0.41019932215069177, 0.41021062767742006, 0.4102119105674364, 0.4102127767176337, 0.4102142290387665, 0.4102146457785856, 0.4102163021008926, 0.4102287486798175, 0.41023253238857393, 0.41023361217474374, 133.28232325887643, 432.11028466781676, 3.5498196487122966, 20.24594925110888, 488.962870817085, 874.141860024994, 15.162561609506222, 47.454028177083096, 15.60380062260259, 1424.013016005501, 3653.009017156264, 113.77780003489326, 72.17661205389398, 119.00422296489543, 161.67673304042452, 127.32026514720165, 158.73720652411438, 287.86413349608677, 154.85382132052828, 330.40943929482285, 249.18606427077654, 67.48735046212649, 81.03820864873788, 465.9765957826914, 1641.7049338298089, 151.56547736622272, 167.159525344231, 5.360289215532484, 4417.467863890398, 16.771151950068838, 0.4100178604376594, 0.4100178604376594, 0.41001786142685664, 0.41001786142685664, 0.41001786142685664, 0.41001786241605387, 0.41001786241605387, 0.41001786241605387, 0.4100178634052511, 0.4100178634052511, 0.41001786538364554, 0.41001786538364554, 0.41001786538364554, 0.41001786637284277, 0.4101517259523101, 0.4101853447824235, 0.41018807999357276, 0.4101936739187456, 0.4101969390385727, 0.41019720995985987, 0.41019932215069177, 0.41021062767742006, 0.4102119105674364, 0.4102127767176337, 0.4102142290387665, 0.4102146457785856, 0.4102163021008926, 0.4102287486798175, 0.41023253238857393, 0.41023361217474374, 133.28232325887643, 432.11028466781676, 3.5498196487122966, 20.24594925110888, 488.962870817085, 874.141860024994, 15.162561609506222, 47.454028177083096, 15.60380062260259, 1424.013016005501, 3653.009017156264, 113.77780003489326, 72.17661205389398, 119.00422296489543, 161.67673304042452, 127.32026514720165, 158.73720652411438, 287.86413349608677, 154.85382132052828, 330.40943929482285, 249.18606427077654, 67.48735046212649, 81.03820864873788, 465.9765957826914, 1641.7049338298089, 151.56547736622272, 167.159525344231, 5.360289215532484, 4417.467863890398, 16.771151950068838], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.1594, -3.5999, -4.725, -4.8773, -5.078, -4.5376, -5.5159, -6.0761, -5.7525, -5.2322, -6.3926, -6.4117, -6.2784, -6.0692, -6.4726, -6.5007, -6.5283, -4.401, -6.5821, -4.5433, -6.634, -6.5938, -6.0645, -6.6699, -6.7198, -6.638, -6.7685, -4.5021, -6.8156, -6.8521, -4.4799, -3.7452, -4.8338, -5.0659, -5.0825, -4.743, -5.7157, -3.4494, -4.3632, -4.6539, -5.3176, -4.7919, -4.3492, -5.8823, -4.8218, -5.0816, -4.2732, -4.8045, -5.8194, -5.0547, -5.0135, -4.7613, -4.8805, -5.1637, -5.1578, -5.4391, -5.9337, -6.1857, -6.227, -6.3087, -6.3451, -6.5427, -6.647, -6.6788, -6.7233, -6.7753, -6.8311, -6.84, -6.8441, -6.8441, -6.8496, -6.8777, -6.9083, -6.9321, -6.9194, -6.969, -6.9443, -6.9828, -6.9901, -5.6025, -7.0013, -7.0495, -7.0512, -6.7946, -7.0794, -5.9095, -5.9132, -4.8167, -5.1841, -5.8321, -5.4567, -5.3721, -5.2153, -5.6849, -5.4492, -6.0567, -5.3815, -6.0568, -5.7375, -6.1734, -5.4322, -6.3463, -4.4774, -5.0843, -5.6127, -5.7098, -6.2842, -4.6033, -5.7576, -5.1487, -4.7576, -5.0681, -5.2495, -5.1432, -5.2523, -5.1528, -4.7369, -4.7155, -5.4305, -5.4196, -5.283, -4.905, -5.2824, -5.3719, -5.3738, -5.2115, -5.4545, -3.4337, -4.3943, -4.9713, -5.0196, -5.2872, -5.2872, -5.305, -5.305, -5.305, -5.4194, -5.5307, -5.7058, -5.7058, -5.7058, -5.7058, -5.7058, -5.7058, -5.7058, -5.7058, -5.7058, -5.7516, -5.9711, -5.9711, -5.9711, -5.9711, -5.989, -5.989, -5.989, -5.989, -5.989, -4.8213, -5.5163, -5.9272, -3.6909, -4.9126, -4.9789, -4.9998, -5.0399, -5.2161, -5.2676, -5.3689, -5.5089, -5.52, -5.5348, -5.5883, -5.6166, -5.7127, -5.7147, -5.8047, -5.8126, -5.8445, -5.9533, -5.9718, -6.0747, -6.0858, -6.0869, -6.1518, -6.1916, -6.2057, -6.2057, -6.2057, -6.2057, -6.2149, -4.0421, -4.8032, -5.5431, -5.6168, -6.055, -6.0163, -6.1196, -4.4295, -4.4295, -4.5128, -4.8198, -4.9509, -5.0339, -5.0837, -5.3297, -5.3297, -5.3478, -5.4411, -5.5536, -5.5699, -5.5699, -5.9039, -6.0075, -6.0075, -6.0075, -6.0075, -6.0075, -6.0075, -6.0075, -6.0145, -6.025, -6.146, -6.146, -6.1532, -6.1548, -6.1678, -6.1884, -5.303, -4.436, -5.5895, -5.6883, -6.7528, -7.0068, -7.2548, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9091, -7.9092, -7.9093, -7.996, -9.1747, -9.1747, -9.1747, -9.1747, -9.1747, -9.1747, -9.1747, -9.1747, -9.1747, -9.1747, -9.1448, -9.1449, -9.166, -9.166, -9.166, -9.166, -9.166, -9.1564, -9.1644, -9.1661, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677, -9.1677], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2214, 0.2214, 0.2213, 0.2213, 0.2212, 0.2211, 0.221, 0.2206, 0.2206, 0.2205, 0.2204, 0.2203, 0.2203, 0.2203, 0.2203, 0.2202, 0.2202, 0.2201, 0.2201, 0.2201, 0.22, 0.22, 0.22, 0.22, 0.2199, 0.2199, 0.2198, 0.2198, 0.2197, 0.2197, 0.2196, 0.2096, 0.2138, 0.2155, 0.208, 0.2033, 0.2127, 0.1819, 0.1896, 0.1942, 0.2071, 0.1942, 0.1693, 0.2093, 0.1723, 0.1746, 0.1036, 0.132, 0.2041, 0.1083, 0.0994, 0.0013, -0.0188, 0.0876, 0.0327, 1.6668, 1.6656, 1.6648, 1.6646, 1.6643, 1.6639, 1.6631, 1.6625, 1.6623, 1.662, 1.6617, 1.6612, 1.6612, 1.6612, 1.6612, 1.6611, 1.6609, 1.6605, 1.6603, 1.6603, 1.6602, 1.6601, 1.6601, 1.66, 1.6599, 1.6599, 1.6595, 1.6595, 1.6592, 1.6592, 1.6552, 1.6504, 1.6252, 1.6248, 1.6361, 1.6212, 1.6164, 1.6077, 1.6031, 1.5572, 1.5978, 1.5468, 1.5968, 1.5679, 1.5977, 1.5238, 1.6137, 1.3549, 1.4221, 1.4966, 1.4779, 1.5865, 1.1721, 1.4329, 1.2499, 1.1228, 1.1233, 1.1609, 1.0701, 0.8206, 0.6154, 0.1247, 0.0471, 0.8963, 0.8219, 0.4255, -0.5282, -0.0919, 0.1386, -0.1157, -1.5802, -0.0979, 5.3975, 5.3736, 5.3442, 5.3409, 5.3199, 5.3199, 5.3183, 5.3183, 5.3183, 5.3075, 5.2958, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2749, 5.2689, 5.2366, 5.2366, 5.2366, 5.2366, 5.2336, 5.2336, 5.2336, 5.2336, 5.2336, 5.1801, 5.0085, 3.3848, 5.6609, 5.6034, 5.598, 5.5963, 5.5928, 5.5749, 5.5701, 5.5578, 5.5404, 5.5388, 5.5369, 5.5289, 5.5253, 5.5105, 5.51, 5.4951, 5.4921, 5.4877, 5.466, 5.4635, 5.4421, 5.4392, 5.4388, 5.4252, 5.4137, 5.4127, 5.4127, 5.4127, 5.4127, 5.4092, 3.8035, 4.3264, 3.9945, 2.508, 4.1052, 3.4212, 3.8818, 6.1069, 6.1069, 6.0999, 6.0673, 6.051, 6.039, 6.0319, 5.9907, 5.9907, 5.9843, 5.9671, 5.9453, 5.9415, 5.9415, 5.856, 5.8255, 5.8255, 5.8255, 5.8255, 5.8255, 5.8255, 5.8255, 5.8232, 5.8178, 5.781, 5.781, 5.7778, 5.777, 5.7732, 5.7561, 5.3062, 4.4891, 5.0536, 4.8365, 6.0986, 5.8382, 5.6325, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 5.007, 4.9673, 4.9088, 3.84, 3.7411, 3.741, 3.741, 3.741, 3.741, 3.741, 3.741, 3.7409, 3.7409, 3.7409, 3.7226, 3.7192, 3.7283, 3.7283, 3.7283, 3.7283, 3.7283, 2.6638, 2.4104, 2.3034, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7481, 3.748, 3.748, 3.748, 3.748, 3.748, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, -2.0356, -3.2118, 1.5899, -0.1511, -3.3355, -3.9164, 0.138, -1.0029, 0.1093, -4.4044, -5.3465, -1.8774, -1.4223, -1.9223, -2.2288, -1.9899, -2.2104, -2.8057, -2.1856, -2.9435, -2.6614, -1.3551, -1.5381, -3.2873, -4.5467, -2.1642, -2.2621, 1.1778, -5.5365, 0.0372, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7484, 3.7481, 3.748, 3.748, 3.748, 3.748, 3.748, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, 3.7479, -2.0356, -3.2118, 1.5899, -0.1511, -3.3355, -3.9164, 0.138, -1.0029, 0.1093, -4.4044, -5.3465, -1.8774, -1.4223, -1.9223, -2.2288, -1.9899, -2.2104, -2.8057, -2.1856, -2.9435, -2.6614, -1.3551, -1.5381, -3.2873, -4.5467, -2.1642, -2.2621, 1.1778, -5.5365, 0.0372]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 4, 1, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 4, 2, 1, 2, 1, 4, 1, 2, 4, 1, 2, 1, 2, 2, 1, 2, 4, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 5, 1, 3, 1, 3, 3, 1, 2, 1, 3, 2, 5, 1, 2, 3, 1, 2, 1, 2, 4, 1, 2, 1, 2, 4, 1, 2, 4, 1, 2, 1, 1, 1, 2, 1, 2, 3, 3, 3, 1, 2, 1, 2, 4, 4, 1, 1, 2, 1, 4, 1, 5, 1, 2, 1, 2, 1, 2, 2, 4, 1, 3, 1, 2, 4, 1, 2, 4, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 4, 5, 4, 5, 1, 2, 1, 2, 1, 2, 2, 2, 5, 4, 4, 1, 4, 1, 3, 3, 1, 2, 2, 2, 4, 3, 5, 1, 2, 1, 2, 1, 2, 2, 5, 5, 1, 2, 1, 2, 5, 2, 1, 4, 1, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 5, 5, 3, 2, 5, 3, 4, 2, 1, 1, 4, 1, 2, 5, 5, 5, 1, 2, 5, 3, 5, 1, 2, 1, 2, 1, 2, 2, 4, 3, 3, 5, 1, 1, 2, 4, 1, 2, 4, 2, 1, 2, 2, 2, 1, 4, 1, 2, 1, 2, 1, 2, 1, 2, 5, 1, 2, 4, 1, 2, 1, 2, 2, 5, 2, 1, 5, 4, 2, 5, 3, 4, 1, 2, 1, 2, 1, 5, 2, 1, 2, 4, 1, 2, 1, 5, 1, 3, 3, 5, 3, 3, 5, 3, 3, 1, 2, 5, 5, 1, 2, 5, 1, 1, 4, 2, 5, 3, 4, 3, 3, 1, 5, 5, 4, 5, 1, 4, 1, 2, 4, 1, 1, 2, 1, 2, 2, 1, 2, 1, 4, 2], \"Freq\": [0.9003444497806513, 0.09753731539290389, 0.9372607280369231, 0.06248404853579487, 0.8451133569808977, 0.9999685229085309, 0.9878519279062498, 0.26995914798074633, 0.7301167865842912, 0.8968834446712061, 0.4490478271405348, 0.5508320012923893, 0.8751439954816106, 0.12469371961764124, 0.9892787502736805, 0.9906297758852715, 0.00900572523532065, 0.601802155549615, 0.051512833470362465, 0.9444019469566453, 0.9904322521285484, 0.9613042593143644, 0.9985863780858214, 0.0014044815444245026, 0.9999975315811647, 0.544921768402851, 0.45703116059593957, 0.98510560633235, 0.031499791455031366, 0.9659936046209618, 0.07107367098378185, 0.9381724569859204, 0.3325176856746795, 0.665035371349359, 0.9990203988607185, 0.0013991882336984853, 0.8968834446712061, 0.8066940618428192, 0.19327045231650877, 0.9587818865893823, 0.9811997854990561, 0.98962910117682, 0.01237036376471025, 0.9974845705290405, 0.6067929275333007, 0.6362717488332309, 0.3590840562722194, 0.9944621140146493, 0.6044518220689183, 0.39254629824015963, 0.8717899167665141, 0.12915406174318728, 0.984713619820891, 0.9745484290256031, 0.02421238332982865, 1.0007169604046893, 0.2167055375188286, 0.7825477743735477, 0.9927786398667409, 0.9879758535529459, 0.863790070970309, 0.1357384397239057, 0.42062198353714053, 0.5794282426276935, 0.9983523629770067, 0.0012182457144319788, 0.3826728949618025, 0.6135961936456488, 0.7041841036983574, 0.9930633606320477, 0.0059823094013978775, 0.8836008857477518, 0.9327854895425277, 0.9611841287421639, 0.0387099590237659, 0.7674632089873463, 1.0136453387705562, 0.7041841036983574, 0.9980373028583162, 0.7041841036983574, 0.9053027155432538, 0.06137800412831188, 0.9382066345327673, 0.9995983565060189, 0.7041841036983574, 1.0039114008873657, 0.598532364512564, 1.0012141665256107, 1.0030216317585523, 0.8968834446712061, 0.2068006867510994, 0.7874333841676477, 1.0011102847409292, 0.9785025872667217, 0.6661898675345299, 0.5365411691547924, 0.4627667583960085, 0.3902538192434173, 0.6085641240677052, 0.9667683880154295, 0.39737060629510407, 0.6015243122815795, 0.8737641543713491, 0.8855181672746, 0.1145495941918774, 0.9982695089898184, 1.000060699321868, 0.04264486206000098, 0.9524019193400219, 0.9823297531643477, 0.01770723160210412, 0.8968834446712061, 0.98510560633235, 0.8195099680525669, 0.8277788308743628, 0.17222966572158394, 0.9830215818028698, 0.017332874238337754, 0.7613511424043461, 0.8974291845901939, 0.9986930877445448, 0.06059062690383508, 0.9419088364141636, 0.7749643261726995, 0.1549928652345399, 0.9990504998786801, 0.9070383644731793, 0.8932608330582361, 0.10681430829066833, 0.41877701552098795, 0.5798450984136756, 0.9918892390298382, 0.007464829644627193, 0.9820691055496112, 1.000672023391648, 0.9995393195732948, 0.8968834446712061, 0.49767883120524786, 0.22119059164677682, 0.276488239558471, 0.9937995516844137, 0.00589442201473555, 0.6072103698766874, 0.8020486340889197, 0.19788076536577023, 0.9828357436932058, 0.8315449983867385, 0.16815175867654267, 0.05199584619732255, 0.9489241931011366, 0.9493764369102541, 0.05057477255109633, 0.9941452930750189, 0.9730709056126575, 0.027200358948595474, 0.10587093224951465, 0.8932859908552798, 0.9404223492997725, 0.8256665038249525, 0.7712891221552229, 0.8256665038249525, 0.011550513585719492, 0.9817936547861569, 0.04344666313693726, 0.9558265890126197, 0.041388270403742156, 0.9556927893227735, 0.9959393373399998, 0.9941756652052233, 0.8337793796721399, 0.6661898675345299, 0.6661898675345299, 0.9028882941577597, 0.07524069117981332, 0.8627888677410317, 0.13273674888323564, 0.9693520909439628, 0.9959156066423819, 0.972487445108892, 0.993632233078579, 0.9983839281890575, 0.5459373117600109, 0.6695530650602366, 0.22318435502007888, 0.06325101290938796, 0.9361149910589418, 0.07851767078254966, 0.9265085152340861, 0.5696410025144528, 0.4280005370243727, 1.0018542254670415, 0.8256665038249525, 0.9618606882703922, 0.34226195810466953, 0.6593046140332056, 0.9863023560488354, 0.013531587201889511, 1.00069027401291, 0.9914495810164687, 0.8315925941541777, 0.16631851883083557, 0.7864050968928974, 0.2138402036871327, 1.0001899407559778, 0.17448540770120724, 0.8248401091329797, 0.7328084607528697, 0.15400657557112668, 0.8433693424133127, 0.9862326077041712, 0.013086319281961259, 0.9997799564142422, 0.4856707970161191, 0.4856707970161191, 0.9890400774636573, 0.7041841036983574, 0.9799843908960071, 0.5911393099304367, 0.7041841036983574, 0.6574745032673022, 1.00710298343857, 1.001039841114464, 0.9996650261780103, 0.8071565428535364, 0.9995044785284962, 0.0006989541807891582, 0.9106455450288314, 0.8058354900370756, 0.8256665038249525, 0.7119946339885809, 0.2891348767466318, 0.9031314772965577, 0.946838996843982, 0.9031314772965577, 0.1162598734253355, 0.8872464024565078, 0.06319118167190244, 0.9352294887441561, 0.9981815512000584, 1.000247851052998, 0.9856466417175429, 0.5547458615500701, 0.9847669427251012, 0.9693520909439628, 0.8256665038249525, 0.996576766046614, 0.9729791366803064, 0.026751193860024138, 0.9688536884648195, 0.9969194608493922, 1.0058681167505172, 0.639112917013093, 1.0053816799295083, 0.9886479193967732, 0.010602122460019016, 0.9891642462248191, 0.9918377923559858, 0.8422904502470484, 0.1531437182267361, 0.09815184474155894, 0.9012123926270411, 0.9540912685258417, 0.045980302097630925, 0.13211085626096994, 0.868157055429231, 0.9517038541454215, 0.047762089334435646, 0.8256665038249525, 0.9980638287108011, 0.0019763640172491114, 0.6699758844965061, 0.8888310397364882, 0.11116351704702188, 0.011563909505331258, 0.982932307953157, 0.980474624882856, 0.9230724787515934, 1.007085409229297, 0.5024275145830174, 0.2512137572915087, 0.9154647219622198, 0.8112829722087976, 0.18028510493528835, 0.8836008857477518, 0.6661898675345299, 0.008547210533030487, 0.9914764218315365, 0.998405976737455, 0.0013473764868251756, 0.9995926028465935, 0.9198488005241908, 0.9928842469987817, 0.08098671957809907, 0.8706072354645649, 0.040493359789049534, 0.9882687112388154, 0.011888006023132315, 1.0009437030665957, 0.9890400774636573, 0.8151290465149271, 0.8836008857477518, 0.7041841036983574, 0.8295381182630629, 0.7041841036983574, 0.98510560633235, 0.5398931813367361, 0.9051921639510299, 0.7041841036983574, 0.8287198828601121, 0.17031973052646474, 0.7721833161965623, 0.598532364512564, 0.9143330344687829, 0.08517074841627019, 0.9746911420759171, 0.6377805908189541, 0.9980083320037149, 0.9736513742824543, 1.0013692893898878, 0.7192689849590248, 0.7934348792319547, 0.1322391465386591, 0.9422607704957429, 0.8836008857477518, 0.5740494578252565, 0.9070383644731793, 0.9114185036622017, 0.8849359602442819, 0.8256665038249525, 1.0000147634138825, 0.7541157997649156, 0.6502430472809145, 0.3490980371832639, 0.8273165341612563, 0.9997273165586484, 0.7826969099171844, 0.21642755463619115, 0.9688675857607028, 0.03129049748493168, 0.9984587781140086, 0.5723596916611319, 0.4292697687458489, 1.0006770706628962, 0.8986791542537936, 0.8281010927405604], \"Term\": [\"absolutely\", \"absolutely\", \"action\", \"action\", \"active\", \"adaptation\", \"admit\", \"alchemy\", \"alchemy\", \"algo\", \"alphonse\", \"alphonse\", \"also\", \"also\", \"amazed\", \"amazing\", \"amazing\", \"america\", \"amestris\", \"amestris\", \"animate\", \"animated\", \"animation\", \"animation\", \"anime\", \"antagonist\", \"antagonist\", \"apartado\", \"arm\", \"arm\", \"armor\", \"armor\", \"armstrong\", \"armstrong\", \"art\", \"art\", \"asi\", \"aspect\", \"aspect\", \"aswell\", \"automail\", \"awesome\", \"awesome\", \"background\", \"basicly\", \"battle\", \"battle\", \"be\", \"become\", \"become\", \"believe\", \"believe\", \"bind\", \"bit\", \"bit\", \"bitch\", \"body\", \"body\", \"boring\", \"bradley\", \"brilliant\", \"brilliant\", \"brother\", \"brother\", \"brotherhood\", \"brotherhood\", \"call\", \"call\", \"cantidad\", \"cast\", \"cast\", \"cet\", \"chang\", \"character\", \"character\", \"christian\", \"clever\", \"como\", \"compare\", \"crear\", \"dan\", \"death\", \"death\", \"definitely\", \"del\", \"depict\", \"desde\", \"deserve\", \"destroy\", \"detalle\", \"die\", \"die\", \"dub\", \"dude\", \"echange\", \"ed\", \"ed\", \"edward\", \"edward\", \"el\", \"elric\", \"elric\", \"en\", \"end\", \"end\", \"enjoy\", \"enjoyment\", \"envy\", \"envy\", \"episode\", \"episode\", \"es\", \"esta\", \"et\", \"even\", \"even\", \"ever\", \"ever\", \"everytime\", \"fab\", \"fan\", \"father\", \"father\", \"fav\", \"fav\", \"favorite\", \"federal\", \"feel\", \"feel\", \"fight\", \"fight\", \"first\", \"first\", \"flask\", \"fly\", \"fma\", \"forma\", \"fuck\", \"fuck\", \"fuck\", \"fullmetal_alchemist\", \"fullmetal_alchemist\", \"generate\", \"get\", \"get\", \"gluttony\", \"go\", \"go\", \"god\", \"god\", \"good\", \"good\", \"government\", \"great\", \"great\", \"greed\", \"greed\", \"hagaren\", \"hasta\", \"hence\", \"hermano\", \"hohenheim\", \"hohenheim\", \"homunculus\", \"homunculus\", \"human\", \"human\", \"human_transmutation\", \"humanity\", \"humble\", \"hypothetically\", \"ight\", \"ill\", \"ill\", \"importance\", \"importance\", \"je\", \"job\", \"join\", \"kill\", \"kimblee\", \"kiss\", \"la\", \"la\", \"law\", \"law\", \"leg\", \"leg\", \"life\", \"life\", \"limb\", \"llevar\", \"los\", \"lose\", \"lose\", \"love\", \"love\", \"lullaby\", \"lust\", \"m\", \"m\", \"make\", \"make\", \"manga\", \"military\", \"military\", \"mon\", \"mother\", \"mother\", \"much\", \"much\", \"music\", \"musical\", \"musical\", \"muy\", \"nada\", \"nation\", \"nietzsche\", \"nombrar\", \"obsess\", \"obtain\", \"opinion\", \"original\", \"originality\", \"overall\", \"overall\", \"overman\", \"para\", \"pena\", \"people\", \"people\", \"pero\", \"personaje\", \"por\", \"power\", \"power\", \"powerful\", \"powerful\", \"pretty\", \"pride\", \"protect\", \"pump\", \"que\", \"qui\", \"quien\", \"read\", \"really\", \"really\", \"realy\", \"recommend\", \"represent\", \"retarded\", \"revenge\", \"review\", \"review\", \"riza_hawkeye\", \"roy\", \"s\", \"s\", \"sacrifice\", \"sacrifice\", \"say\", \"say\", \"scar\", \"scar\", \"see\", \"see\", \"sentido\", \"series\", \"series\", \"shippuden\", \"show\", \"show\", \"sin\", \"sin\", \"sloth\", \"smartly\", \"soldier\", \"solo\", \"solo\", \"sometime\", \"son\", \"son\", \"sont\", \"sorceror\", \"soul\", \"soul\", \"sound\", \"sound\", \"soundtrack\", \"spiritual\", \"state_alchemist\", \"stone\", \"stone\", \"stone\", \"story\", \"story\", \"style\", \"su\", \"substantially\", \"sur\", \"sus\", \"symbolic\", \"tambien\", \"tan\", \"tank\", \"tant\", \"tengo\", \"thing\", \"thing\", \"tiene\", \"tienen\", \"time\", \"time\", \"todo\", \"tokyo\", \"top\", \"trisha_lullaby\", \"truth\", \"ubermensch\", \"un\", \"un\", \"una\", \"une\", \"unfocused\", \"uno\", \"vain\", \"ve\", \"ver\", \"version\", \"villian\", \"want\", \"want\", \"wanting\", \"watch\", \"way\", \"way\", \"well\", \"well\", \"woman\", \"world\", \"world\", \"worth\", \"wtf\", \"zany\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 8, 6, 7, 1, 5, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1952819382909622087422772407\", ldavis_el1952819382909622087422772407_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1952819382909622087422772407\", ldavis_el1952819382909622087422772407_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1952819382909622087422772407\", ldavis_el1952819382909622087422772407_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.331220 -0.152509       1        1  80.130730\n",
       "1     -0.272789  0.171455       2        1  18.849718\n",
       "7      0.154398 -0.031642       3        1   0.445994\n",
       "5      0.108530  0.002658       4        1   0.339214\n",
       "6      0.105219  0.002442       5        1   0.203842\n",
       "0      0.079128  0.002524       6        1   0.020376\n",
       "4      0.078367  0.002536       7        1   0.005207\n",
       "2      0.078367  0.002536       8        1   0.004918, topic_info=          Term         Freq        Total Category  logprob  loglift\n",
       "10       anime  3653.000000  3653.000000  Default  30.0000  30.0000\n",
       "4      alchemy   488.000000   488.000000  Default  29.0000  29.0000\n",
       "348     edward   517.000000   517.000000  Default  28.0000  28.0000\n",
       "264      watch  2087.000000  2087.000000  Default  27.0000  27.0000\n",
       "23     brother   465.000000   465.000000  Default  26.0000  26.0000\n",
       "..         ...          ...          ...      ...      ...      ...\n",
       "25        call     0.000856   151.565477   Topic8  -9.1677  -2.1642\n",
       "26        cast     0.000856   167.159525   Topic8  -9.1677  -2.2621\n",
       "27       chang     0.000856     5.360289   Topic8  -9.1677   1.1778\n",
       "28   character     0.000856  4417.467864   Topic8  -9.1677  -5.5365\n",
       "29      clever     0.000856    16.771152   Topic8  -9.1677   0.0372\n",
       "\n",
       "[421 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "0         1  0.900344  absolutely\n",
       "0         2  0.097537  absolutely\n",
       "1         1  0.937261      action\n",
       "1         2  0.062484      action\n",
       "2         1  0.845113      active\n",
       "...     ...       ...         ...\n",
       "269       1  0.572360       world\n",
       "269       2  0.429270       world\n",
       "2405      1  1.000677       worth\n",
       "4577      4  0.898679         wtf\n",
       "1322      2  0.828101        zany\n",
       "\n",
       "[345 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 2, 8, 6, 7, 1, 5, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a visualization of the topic models\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data frame as a CSV file\n",
    "# job_datas.to_csv(r'D:\\UMD Senior College Work\\Spring 2021\\INST447-0101\\Programming Assignment 2\\Chan_Matthew_INST447_PA2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 9 Topic Modelling\n",
    "# ner_corpus = ' '.join(ner_df['Name'])\n",
    "# corp = open(r'D:\\UMD Senior College Work\\Spring 2021\\INST447-0101\\Week 9\\corpus.txt',\"w\")\n",
    "# corp.writelines(ner_corpus)\n",
    "# corp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
